## introduction
이 논문 이전까지는 비전 분야에서 CNN이 항상 백본으로 활용되었다. 이 논문을 통해 NLP에서 백본으로 사용하던 Transformer를 비전의 백본으로 활용하는 시도를 하였다. Transformer는 시퀀스 모델링 및 변환 작업에 설계된 것으로 데이터내 장기적 의존성을 모델링하며 주로 어텐션 메커니즘을 활용한다.
비전과 언어라는 두 도메인 간의 차이가 있기에 Transformer를 그대로 비전 분야에 적용하기는 어렵다. 2가지 원인이 있다.
#### 1. 스케일(Scale) 문제
첫번째 원인은 스케일 문제이다. NLP에서는 단어 토큰을 고정된 단위로 쪼개서 처리한다. 고정된 단위로 처리해도 텍스트를 처리하는데 있어서는 문제가 없었다. 하지만 비전에서는 객체들의 크기가 다양하므로 고정된 단위로는 처리하기 어렵다.
#### 2. 해상도 문제
이미지의 픽셀 수는 텍스트의 단어보다 훨씬 많기 대문에 고해상도 이미지 처리시 매우 높은 복잡도를 갖는다. 

위의 두 문제를 해결하기 위해 계층적 피처 맵을 구성한다. 자세한 내용은 아래에서 확인해보자.

## Method
